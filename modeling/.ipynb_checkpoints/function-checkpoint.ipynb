{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting function.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile function.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from scrapy.http import TextResponse\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Kkma\n",
    "import pickle\n",
    "\n",
    "def make_df_train(keyword, item_count_start=0, item_count_end=100):\n",
    "    \n",
    "    search_url = \"http://www.coupang.com/np/search?q={}&isPriceRange=false&page=1&sorter=scoreDesc&listSize=100\".format(keyword)\n",
    "    rep = requests.get(search_url)\n",
    "    response = TextResponse(rep.url, body=rep.text, encoding='utf-8')\n",
    "\n",
    "    # 상품마다의 링크를 불러오기에 앞서 아이템 Top100 리스트 불러오기\n",
    "    products = json.loads(response.xpath('//*[@id=\"productList\"]/@data-products').extract()[0])['indexes'][item_count_start:item_count_end]\n",
    "    products = list(set(products))\n",
    "    print(\"총 {}개의 상품에서 중복제거 후 {}개의 상품 크롤링\".format(item_count_end-item_count_start,len(products)))\n",
    "    \n",
    "    df = pd.DataFrame(columns=['rating', \"item_nbr\", \"item\", \"option\", \"date\", \"name\", \"re_title\", 'review']) \n",
    "\n",
    "    top100_review_total_cnt = 0\n",
    "    review_count = 0\n",
    "    no_review_cnt = 0\n",
    "    \n",
    "    for product in products:\n",
    "        \n",
    "        # Top100 상품마다의 상품평 개수(나중에 불러오는 정보라 상품링크 안에서는 xpath로 바로 가져올 수 없음)\n",
    "        try:\n",
    "            review_count = int(response.xpath('//*[@id=\"{}\"]/a/dl/dd/div/div[4]/div[2]/span[2]/text()'.format(product)).extract()[0].strip(\"()\"))\n",
    "            top100_review_total_cnt += review_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            no_review_cnt += 1\n",
    "        \n",
    "        # product for문 안에서 수행하는 코드    \n",
    "        def make_url(product, review_count):\n",
    "            page_count = (review_count//100)+1\n",
    "            review_urls = []\n",
    "            for page in range(1, page_count+1):\n",
    "                review_urls.append('http://www.coupang.com/vp/product/reviews?productId={}&page={}&size=100&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=2&ratingSummary=true'.format(product, page))\n",
    "                # size는 100이 최대로 설정되어 있음\n",
    "            return review_urls\n",
    "\n",
    "\n",
    "        # Top100 상품마다의 크롤링할 url(리뷰 크롤링은 '상품평 보기' 클릭 후 나타나는 reviews Request URL에서 해야함)\n",
    "#         review_urls[product] = make_url(product, review_count)\n",
    "        review_url = make_url(product, review_count) # 리스트로 반환됨\n",
    "\n",
    "        for url in review_url:\n",
    "\n",
    "            review_url = url\n",
    "            review_rep = requests.get(review_url)\n",
    "            review_response = TextResponse(review_rep.url, body=review_rep.text, encoding='utf-8')        \n",
    "\n",
    "            # Top100 상품마다의 상품평 개수\n",
    "            review_total_cnt = int(review_response.xpath('/html/body/div[2]/@data-review-total-count').extract()[0])\n",
    "\n",
    "            # Top100 상품마다 한 page의 상품평 개수\n",
    "            review_url_cnt = int(float(review_response.xpath('count(/html/body/article)').extract()[0]))\n",
    "\n",
    "            if review_url_cnt < 100:          \n",
    "                for i in range(1, review_url_cnt+1): # 한개의 review_url에서 100개를 훑고 그 다음 review_url로 넘어가면 됨\n",
    "                    item_nbr = product\n",
    "\n",
    "                    date = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[2]/text()'.format(i)).extract()[0]\n",
    "\n",
    "                    name = review_response.xpath('/html/body/article[{}]/div[1]/div[2]/span/text()'.format(i)).extract()[0][:-1]\n",
    "\n",
    "                    item_option_ls = review_response.xpath('/html/body/article[{}]/div[1]/div[4]/text()'.format(i)).extract()[0].split(\",\")\n",
    "                    if len(item_option_ls) == 1:\n",
    "                        item = item_option_ls[0]\n",
    "\n",
    "                    else:    \n",
    "                        item = item_option_ls[0]\n",
    "                        option = item_option_ls[1]\n",
    "\n",
    "                    if review_response.xpath('/html/body/article[{}]/div[3]/@class'.format(i)).extract()[0] == 'sdp-review__article__list__headline':\n",
    "                        re_title = review_response.xpath('/html/body/article[{}]/div[3]/text()'.format(i)).extract()\n",
    "                        review = review_response.xpath('/html/body/article[{}]/div[4]/div/text()'.format(i)).extract()\n",
    "\n",
    "                    else:\n",
    "                        re_title = ['.']\n",
    "                        review = review_response.xpath('/html/body/article[{}]/div[3]/div/text()'.format(i)).extract()\n",
    "\n",
    "                    rating = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[1]/div/@data-rating'.format(i)).extract()[0]\n",
    "\n",
    "                    df.loc[len(df)] = {'rating':rating, 'item_nbr':item_nbr, 'item':item, 'option':option, 'date':date, 'name':name, 're_title':re_title, 'review':review}\n",
    "\n",
    "            else:\n",
    "                for i in range(1, 101):\n",
    "                    item_nbr = product\n",
    "\n",
    "                    date = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[2]/text()'.format(i)).extract()[0]\n",
    "\n",
    "                    name = review_response.xpath('/html/body/article[{}]/div[1]/div[2]/span/text()'.format(i)).extract()[0][:-1]\n",
    "\n",
    "                    item_option_ls = review_response.xpath('/html/body/article[{}]/div[1]/div[4]/text()'.format(i)).extract()[0].split(\",\")\n",
    "                    if len(item_option_ls) == 1:\n",
    "                        item = item_option_ls[0]\n",
    "\n",
    "                    else:    \n",
    "                        item = item_option_ls[0]\n",
    "                        option = item_option_ls[1]\n",
    "\n",
    "                    if review_response.xpath('/html/body/article[{}]/div[3]/@class'.format(i)).extract()[0] == 'sdp-review__article__list__headline':\n",
    "                        re_title = review_response.xpath('/html/body/article[{}]/div[3]/text()'.format(i)).extract()\n",
    "                        review = review_response.xpath('/html/body/article[{}]/div[4]/div/text()'.format(i)).extract()\n",
    "\n",
    "                    else:\n",
    "                        re_title = ['.']\n",
    "                        review = review_response.xpath('/html/body/article[{}]/div[3]/div/text()'.format(i)).extract()\n",
    "\n",
    "                    rating = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[1]/div/@data-rating'.format(i)).extract()[0]\n",
    "\n",
    "                    df.loc[len(df)] = {'rating':rating, 'item_nbr':item_nbr, 'item':item, 'option':option, 'date':date, 'name':name, 're_title':re_title, 'review':review}\n",
    "\n",
    "    print(\"{}개 상품 중 review가 없는 상품 수 : {}\".format(item_count_end-item_count_start, no_review_cnt))\n",
    "    \n",
    "    \n",
    "    df['re_title_filtered'] = df['re_title'].apply(re_title_filter)\n",
    "    df['review_filtered'] = df['review'].apply(review_filter)\n",
    "    df['full_review'] = df['re_title_filtered']+df['review_filtered']\n",
    "    df['pos'] = df['full_review'].apply(kkma_pos)\n",
    "    df['pos_filtered'] = df['pos'].apply(kkma_pos_filter)\n",
    "    df['rating_filtered'] = df['rating'].apply(rating_filter)\n",
    "    \n",
    "    # 'pos_filtered' == 0인 데이터 삭제\n",
    "    idx = []\n",
    "    for i in range(len(df)):\n",
    "        if len(df['pos_filtered'][i][0]) == 0: # 리스트 안의 문자열의 길이가 0인지를 확인\n",
    "            idx.append(i)\n",
    "    df = df.drop(index=idx).reset_index()\n",
    "    \n",
    "    print(\"{}'s Top{} Review Total Count : {}\".format(keyword, item_count_end, top100_review_total_cnt))\n",
    "    print(\"{}'s Top{} Filtered Review Count : {}\".format(keyword, item_count_end, len(df)))\n",
    "    \n",
    "    df_fin = df[['rating', 'rating_filtered', 'item_nbr', 'item', 'option', 'date', 'name', 'full_review', 'pos', 'pos_filtered']]\n",
    "    \n",
    "    return df_fin\n",
    "\n",
    "def test_review_cnt(link):\n",
    "    import requests\n",
    "    from scrapy.http import TextResponse\n",
    "    import json\n",
    "    \n",
    "    input_url = link.split('?')[0]\n",
    "    product = link.split('?')[0].split(\"/\")[5]\n",
    "    \n",
    "    reveiw_cnt_url = 'http://www.coupang.com/vp/product/reviews?productId={}&page=1&size=100&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=2&ratingSummary=true'.format(product)\n",
    "    reveiw_cnt_rep = requests.get(reveiw_cnt_url)\n",
    "    reveiw_cnt_response = TextResponse(reveiw_cnt_rep.url, body=reveiw_cnt_rep.text, encoding='utf-8')\n",
    "    \n",
    "    item_name = reveiw_cnt_response.xpath('/html/body/article[1]/div[1]/div[4]/text()').extract()[0].split(',')[0]\n",
    "    review_total_cnt = int(reveiw_cnt_response.xpath('/html/body/div[2]/@data-review-total-count').extract()[0])\n",
    "  \n",
    "    return \"{}'s Review Total Count : {}\".format(item_name, review_total_cnt)\n",
    "\n",
    "def make_df_test(link):\n",
    "    import requests\n",
    "    from scrapy.http import TextResponse\n",
    "    import json\n",
    "    \n",
    "    input_url = link.split('?')[0]\n",
    "    product = link.split('?')[0].split(\"/\")[5]\n",
    "    \n",
    "    # 상품마다의 링크를 불러오기에 앞서 아이템 Top36 리스트 불러오기\n",
    "#     products = json.loads(response.xpath('//*[@id=\"productList\"]/@data-products').extract()[0])['indexes'][:36]\n",
    "\n",
    "    df = pd.DataFrame(columns=['rating', \"item_nbr\", \"item\", \"option\", \"date\", \"name\", \"re_title\", 'review']) \n",
    "\n",
    "    reveiw_cnt_url = 'http://www.coupang.com/vp/product/reviews?productId={}&page=1&size=100&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=2&ratingSummary=true'.format(product)\n",
    "    reveiw_cnt_rep = requests.get(reveiw_cnt_url)\n",
    "    reveiw_cnt_response = TextResponse(reveiw_cnt_rep.url, body=reveiw_cnt_rep.text, encoding='utf-8')\n",
    "    \n",
    "    item_name = reveiw_cnt_response.xpath('/html/body/article[1]/div[1]/div[4]/text()').extract()[0].split(',')[0]\n",
    "    review_total_cnt = int(reveiw_cnt_response.xpath('/html/body/div[2]/@data-review-total-count').extract()[0])\n",
    "\n",
    "    def make_url(product, review_total_cnt):\n",
    "        page_count = (review_total_cnt//100)+1\n",
    "        review_urls = []\n",
    "        for page in range(1, page_count+1):\n",
    "            review_urls.append('http://www.coupang.com/vp/product/reviews?productId={}&page={}&size=100&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=2&ratingSummary=true'.format(product, page))\n",
    "            # size는 100이 최대로 설정되어 있음\n",
    "        return review_urls\n",
    "\n",
    "    review_url = make_url(product, review_total_cnt) # 리스트로 반환됨\n",
    "\n",
    "    for url in review_url:\n",
    "\n",
    "        review_url = url\n",
    "        review_rep = requests.get(review_url)\n",
    "        review_response = TextResponse(review_rep.url, body=review_rep.text, encoding='utf-8')        \n",
    "\n",
    "        # Top36 상품마다의 상품평 개수\n",
    "        review_total_cnt = int(review_response.xpath('/html/body/div[2]/@data-review-total-count').extract()[0])\n",
    "\n",
    "        # Top36 상품마다 한 page의 상품평 개수\n",
    "        review_url_cnt = int(float(review_response.xpath('count(/html/body/article)').extract()[0]))\n",
    "\n",
    "        if review_url_cnt < 100:          \n",
    "            for i in range(1, review_url_cnt+1): # 한개의 review_url에서 100개를 훑고 그 다음 review_url로 넘어가면 됨\n",
    "                item_nbr = product\n",
    "\n",
    "                date = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[2]/text()'.format(i)).extract()[0]\n",
    "\n",
    "                name = review_response.xpath('/html/body/article[{}]/div[1]/div[2]/span/text()'.format(i)).extract()[0][:-1]\n",
    "\n",
    "                item_option_ls = review_response.xpath('/html/body/article[{}]/div[1]/div[4]/text()'.format(i)).extract()[0].split(\",\")\n",
    "                if len(item_option_ls) == 1:\n",
    "                    item = item_option_ls[0]\n",
    "\n",
    "                else:    \n",
    "                    item = item_option_ls[0]\n",
    "                    option = item_option_ls[1]\n",
    "\n",
    "                if review_response.xpath('/html/body/article[{}]/div[3]/@class'.format(i)).extract()[0] == 'sdp-review__article__list__headline':\n",
    "                    re_title = review_response.xpath('/html/body/article[{}]/div[3]/text()'.format(i)).extract()\n",
    "                    review = review_response.xpath('/html/body/article[{}]/div[4]/div/text()'.format(i)).extract()\n",
    "\n",
    "                else:\n",
    "                    re_title = ['.']\n",
    "                    review = review_response.xpath('/html/body/article[{}]/div[3]/div/text()'.format(i)).extract()\n",
    "\n",
    "                rating = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[1]/div/@data-rating'.format(i)).extract()[0]\n",
    "\n",
    "                df.loc[len(df)] = {'rating':rating, 'item_nbr':item_nbr, 'item':item, 'option':option, 'date':date, 'name':name, 're_title':re_title, 'review':review}\n",
    "\n",
    "        else:\n",
    "            for i in range(1, 101):\n",
    "                item_nbr = product\n",
    "\n",
    "                date = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[2]/text()'.format(i)).extract()[0]\n",
    "\n",
    "                name = review_response.xpath('/html/body/article[{}]/div[1]/div[2]/span/text()'.format(i)).extract()[0][:-1]\n",
    "\n",
    "                item_option_ls = review_response.xpath('/html/body/article[{}]/div[1]/div[4]/text()'.format(i)).extract()[0].split(\",\")\n",
    "                if len(item_option_ls) == 1:\n",
    "                    item = item_option_ls[0]\n",
    "\n",
    "                else:    \n",
    "                    item = item_option_ls[0]\n",
    "                    option = item_option_ls[1]\n",
    "\n",
    "                if review_response.xpath('/html/body/article[{}]/div[3]/@class'.format(i)).extract()[0] == 'sdp-review__article__list__headline':\n",
    "                    re_title = review_response.xpath('/html/body/article[{}]/div[3]/text()'.format(i)).extract()\n",
    "                    review = review_response.xpath('/html/body/article[{}]/div[4]/div/text()'.format(i)).extract()\n",
    "\n",
    "                else:\n",
    "                    re_title = ['.']\n",
    "                    review = review_response.xpath('/html/body/article[{}]/div[3]/div/text()'.format(i)).extract()\n",
    "\n",
    "                rating = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[1]/div/@data-rating'.format(i)).extract()[0]\n",
    "\n",
    "                df.loc[len(df)] = {'rating':rating, 'item_nbr':item_nbr, 'item':item, 'option':option, 'date':date, 'name':name, 're_title':re_title, 'review':review}\n",
    "    \n",
    "    df['re_title_filtered'] = df['re_title'].apply(re_title_filter)\n",
    "    df['review_filtered'] = df['review'].apply(review_filter)\n",
    "    df['full_review'] = df['re_title_filtered']+df['review_filtered']\n",
    "    df['pos'] = df['full_review'].apply(kkma_pos)\n",
    "    df['pos_filtered'] = df['pos'].apply(kkma_pos_filter)\n",
    "    df['rating_filtered'] = df['rating'].apply(rating_filter)\n",
    "    \n",
    "    # 'pos_filtered' == 0인 데이터 삭제\n",
    "    idx = []\n",
    "    for i in range(len(df)):\n",
    "        if len(df['pos_filtered'][i][0]) == 0: # 리스트 안의 문자열의 길이가 0인지를 확인\n",
    "            idx.append(i)\n",
    "    df = df.drop(index=idx).reset_index()\n",
    "    \n",
    "    print(\"{}'s Review Total Count : {}\".format(item_name, review_total_cnt))\n",
    "    print(\"{}'s Filtered Review Count : {}\".format(item_name, len(df)))\n",
    "    \n",
    "    df_fin = df[['rating', 'rating_filtered', 'item_nbr', 'item', 'option', 'date', 'name', 'full_review', 'pos', 'pos_filtered']]\n",
    "    \n",
    "    return df_fin\n",
    "\n",
    "def re_title_filter(a):\n",
    "    for i in range(len(a[0].split('\\n'))):\n",
    "        if len(a[0].split('\\n')[i].strip()) != 0:\n",
    "            return a[0].split('\\n')[i].strip()\n",
    "        else:\n",
    "            return '.'\n",
    "\n",
    "def review_filter(a):\n",
    "    s = ''\n",
    "    for i in range(len(a)):\n",
    "        for ii in range(len(a[i].split('\\n'))):\n",
    "            if a[i].split('\\n')[ii].strip() != 0:\n",
    "                s += a[i].split('\\n')[ii].strip() + ' '\n",
    "    return s\n",
    "\n",
    "def kkma_pos(a):\n",
    "    kkma = Kkma()\n",
    "    return kkma.pos(a)\n",
    "\n",
    "def kkma_pos_filter(a):\n",
    "    \"\"\"\n",
    "    df['pos']를 받아 품사 필터링을 거쳐 해당 키워드 리스트 반환\n",
    "    \"\"\"\n",
    "    pos_ls = ['NNG','NNP','VA','UN','XR','MAG','ECE']\n",
    "    ls = []\n",
    "    s = \"\"\n",
    "    for i in range(len(a)):\n",
    "        #NNG(보통 명사), NNP(고유 명사), VA(형용사), XR(어근), MAG(일반 부사), UN(명사추정범주)\n",
    "        if a[i][1] in pos_ls:\n",
    "            s += a[i][0] + ','\n",
    "    ls.append(s)\n",
    "    return ls\n",
    "\n",
    "def rating_filter(a):\n",
    "    if a == '3' or a == '4' or a == '5':\n",
    "        return 1\n",
    "        # 긍정\n",
    "    else:\n",
    "        return 0\n",
    "        # 부정\n",
    "        \n",
    "def Vectorizer_train(df_train, keyword, stop_words=None):\n",
    "    \"\"\"\n",
    "    df_train의 'pos_filtered' column을 받아 vectorized df를 생성해주는 함수\n",
    "    \"\"\"\n",
    "    train_corpus = []\n",
    "    for i in range(len(df_train['pos_filtered'])):\n",
    "        train_corpus.append(df_train['pos_filtered'][i][0])\n",
    "\n",
    "    vect = CountVectorizer(token_pattern=r\"\\b\\w+\\b\", stop_words=stop_words) # 한 글자도 corpus에 포함될 수 있게 해주는 정규표현식\n",
    "    vect.fit(train_corpus)\n",
    "    \n",
    "    pickle.dump(vect, open(\"save_vect_pkl/vect_{}.pkl\".format(keyword), \"wb\"))\n",
    "\n",
    "    vect_ls = []\n",
    "    for i in range(len(df_train)):\n",
    "        vect_ls.append(vect.transform(df_train['pos_filtered'][i]).toarray()[0])\n",
    "        # 리스트안의 리스트로 반환되기 때문에 vect_ls 안에 append하기 전에 [0]로 꺼내줌\n",
    "    \n",
    "    # 문자열 하나를 문장으로 간주\n",
    "    # corpus에는 여러 문장이 하나의 리스트 안의 문자열 요소로 들어가야 하고, ['an apple is red', 'the boy is young']\n",
    "    # transform할때는 한 문장이 하나의 리스트 안의 문자열 요소로 들어가야 함 ['an apple is red']\n",
    "    \n",
    "    df_vec = pd.DataFrame(vect_ls)\n",
    "    \n",
    "    return df_vec\n",
    "\n",
    "def Vectorizer_test(df_input, keyword):\n",
    "    \"\"\"\n",
    "    df_input의 'pos_filtered' column을 받아 vectorized df를 생성해주는 함수\n",
    "    df와 vect.vocabulary_를 반환\n",
    "    \"\"\"\n",
    "    vect = pickle.load(open(\"save_vect_pkl/vect_{}.pkl\".format(keyword), \"rb\"))\n",
    "    \n",
    "    vect_ls = []\n",
    "    for i in range(len(df_input)):\n",
    "        vect_ls.append(vect.transform(df_input['pos_filtered'][i]).toarray()[0])\n",
    "        # 리스트안의 리스트로 반환되기 때문에 vect_ls 안에 append하기 전에 [0]로 꺼내줌\n",
    "    \n",
    "    # 문자열 하나를 문장으로 간주\n",
    "    # corpus에는 여러 문장이 하나의 리스트 안의 문자열 요소로 들어가야 하고, ['an apple is red', 'the boy is young']\n",
    "    # transform할때는 한 문장이 하나의 리스트 안의 문자열 요소로 들어가야 함 ['an apple is red']\n",
    "    \n",
    "    df_vec = pd.DataFrame(vect_ls)\n",
    "\n",
    "    return df_vec, vect.vocabulary_ \n",
    "    \n",
    "def top_word_negative(X_test, y_test_pred, voca, word_cnt=15):\n",
    "    y_test_pred = pd.DataFrame(y_test_pred, columns=['prediction'])\n",
    "    pred_n_test = pd.concat([y_test_pred, X_test], axis=1)\n",
    "    top_word = pd.DataFrame(pred_n_test[pred_n_test['prediction']==0].sum().sort_values(ascending=False)[:word_cnt], columns=['count']).reset_index()\n",
    "    # reset_index()하면 원래 series에서 갖고있던 index를 value로 만들어줌\n",
    "\n",
    "    def match_word(a):\n",
    "        for key, value in voca.items():\n",
    "            if value == a:\n",
    "                return key\n",
    "\n",
    "    top_word['word'] = top_word['index'].apply(match_word)\n",
    "    top_word['pos'] = top_word['word'].apply(kkma_pos)\n",
    "    return top_word[['word', 'count']] # 나중에 품사 명사인 것, 의미있는 명사만 필터링해서 보여주도록 개선\n",
    "\n",
    "\n",
    "def top_word_positive(X_test, y_test_pred, voca, word_cnt=15):\n",
    "    y_test_pred = pd.DataFrame(y_test_pred, columns=['prediction'])\n",
    "    pred_n_test = pd.concat([y_test_pred, X_test], axis=1)\n",
    "    top_word = pd.DataFrame(pred_n_test[pred_n_test['prediction']==1].sum().sort_values(ascending=False), columns=['count']).reset_index()\n",
    "    # reset_index()하면 원래 series에서 갖고있던 index를 value로 만들어줌\n",
    "    top_word_ = top_word[top_word['index'] != 'prediction'].reset_index(drop=True)\n",
    "    top_word_ = top_word_[:word_cnt]\n",
    "    \n",
    "    def match_word(a):\n",
    "        for key, value in voca.items():\n",
    "            if value == a:\n",
    "                return key\n",
    "\n",
    "    top_word_['word'] = top_word_['index'].apply(match_word)\n",
    "    top_word_['pos'] = top_word_['word'].apply(kkma_pos)\n",
    "    return top_word_[['word', 'count']]\n",
    "\n",
    "\n",
    "def review_cnt_check(keyword, item_count_start=0, item_count_end=100):\n",
    "    import requests\n",
    "    from scrapy.http import TextResponse\n",
    "    import json\n",
    "    search_url = \"http://www.coupang.com/np/search?q={}&isPriceRange=false&page=1&sorter=scoreDesc&listSize=100\".format(keyword)\n",
    "    rep = requests.get(search_url)\n",
    "    response = TextResponse(rep.url, body=rep.text, encoding='utf-8')\n",
    "\n",
    "    # 상품마다의 링크를 불러오기에 앞서 아이템 Top100 리스트 불러오기\n",
    "    products = json.loads(response.xpath('//*[@id=\"productList\"]/@data-products').extract()[0])['indexes'][item_count_start:item_count_end]\n",
    "    \n",
    "    review_total_cnt = 0\n",
    "    \n",
    "    for idx, product in enumerate(products):\n",
    "        \n",
    "        # Top100 상품마다의 상품평 개수(나중에 불러오는 정보라 상품링크 안에서는 xpath로 바로 가져올 수 없음)\n",
    "        try:\n",
    "            review_count = int(response.xpath('//*[@id=\"{}\"]/a/dl/dd/div/div[4]/div[2]/span[2]/text()'.format(product)).extract()[0].strip(\"()\"))\n",
    "            review_total_cnt += review_count\n",
    "            print('{}번째 item {}의 review 수 : {}'.format(idx, product, review_count))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('No reviews')\n",
    "            \n",
    "    print('{}번째부터 {}번째 item의 총 review 수 : {}'.format(item_count_start, item_count_end-1, review_total_cnt))\n",
    "    \n",
    "    \n",
    "def neg_or_pos(y_test_pred):\n",
    "    \"\"\"\n",
    "    y_test_pred를 받아서 negative 댓글 개수와 positive 댓글 개수를 int로 반환\n",
    "    \"\"\"\n",
    "    y_test_pred = pd.DataFrame(y_test_pred, columns=['prediction'])\n",
    "    neg_or_pos = y_test_pred.groupby(by='prediction').size().reset_index(name='count')\n",
    "    neg = list(neg_or_pos[neg_or_pos['prediction']==0]['count'].values)[0]\n",
    "    pos = list(neg_or_pos[neg_or_pos['prediction']==1]['count'].values)[0]\n",
    "    return neg, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting function_front.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile function_front.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from scrapy.http import TextResponse\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Kkma\n",
    "import pickle\n",
    "\n",
    "def review_cnt_check(keyword, item_count_start=0, item_count_end=100):\n",
    "\n",
    "    search_url = \"http://www.coupang.com/np/search?q={}&isPriceRange=false&page=1&sorter=scoreDesc&listSize=100\".format(keyword)\n",
    "    rep = requests.get(search_url)\n",
    "    response = TextResponse(rep.url, body=rep.text, encoding='utf-8')\n",
    "\n",
    "    # 상품마다의 링크를 불러오기에 앞서 아이템 Top100 리스트 불러오기\n",
    "    products = json.loads(response.xpath('//*[@id=\"productList\"]/@data-products').extract()[0])['indexes'][item_count_start:item_count_end]\n",
    "    \n",
    "    review_total_cnt = 0\n",
    "    \n",
    "    for idx, product in enumerate(products):\n",
    "        \n",
    "        # Top100 상품마다의 상품평 개수(나중에 불러오는 정보라 상품링크 안에서는 xpath로 바로 가져올 수 없음)\n",
    "        try:\n",
    "            review_count = int(response.xpath('//*[@id=\"{}\"]/a/dl/dd/div/div[4]/div[2]/span[2]/text()'.format(product)).extract()[0].strip(\"()\"))\n",
    "            review_total_cnt += review_count\n",
    "            print('{}번째 item {}의 review 수 : {}'.format(idx, product, review_count))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('No reviews')\n",
    "            \n",
    "    print('{}번째부터 {}번째 item의 총 review 수 : {}'.format(item_count_start, item_count_end-1, review_total_cnt))\n",
    "\n",
    "def make_df_train(keyword, item_count_start=0, item_count_end=100):\n",
    "    \n",
    "    search_url = \"http://www.coupang.com/np/search?q={}&isPriceRange=false&page=1&sorter=scoreDesc&listSize=100\".format(keyword)\n",
    "    rep = requests.get(search_url)\n",
    "    response = TextResponse(rep.url, body=rep.text, encoding='utf-8')\n",
    "\n",
    "    # 상품마다의 링크를 불러오기에 앞서 아이템 Top100 리스트 불러오기\n",
    "    products = json.loads(response.xpath('//*[@id=\"productList\"]/@data-products').extract()[0])['indexes'][item_count_start:item_count_end]\n",
    "    products = list(set(products))\n",
    "    print(\"총 {}개의 상품에서 중복제거 후 {}개의 상품 크롤링\".format(item_count_end-item_count_start,len(products)))\n",
    "    \n",
    "    df = pd.DataFrame(columns=['rating', \"item_nbr\", \"item\", \"option\", \"date\", \"name\", \"re_title\", 'review']) \n",
    "\n",
    "    top100_review_total_cnt = 0\n",
    "    review_count = 0\n",
    "    no_review_cnt = 0\n",
    "    \n",
    "    for product in products:\n",
    "        \n",
    "        # Top100 상품마다의 상품평 개수(나중에 불러오는 정보라 상품링크 안에서는 xpath로 바로 가져올 수 없음)\n",
    "        try:\n",
    "            review_count = int(response.xpath('//*[@id=\"{}\"]/a/dl/dd/div/div[4]/div[2]/span[2]/text()'.format(product)).extract()[0].strip(\"()\"))\n",
    "            top100_review_total_cnt += review_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            no_review_cnt += 1\n",
    "        \n",
    "        # product for문 안에서 수행하는 코드    \n",
    "        def make_url(product, review_count):\n",
    "            page_count = (review_count//100)+1\n",
    "            review_urls = []\n",
    "            for page in range(1, page_count+1):\n",
    "                review_urls.append('http://www.coupang.com/vp/product/reviews?productId={}&page={}&size=100&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=2&ratingSummary=true'.format(product, page))\n",
    "                # size는 100이 최대로 설정되어 있음\n",
    "            return review_urls\n",
    "\n",
    "\n",
    "        # Top100 상품마다의 크롤링할 url(리뷰 크롤링은 '상품평 보기' 클릭 후 나타나는 reviews Request URL에서 해야함)\n",
    "#         review_urls[product] = make_url(product, review_count)\n",
    "        review_url = make_url(product, review_count) # 리스트로 반환됨\n",
    "\n",
    "        for url in review_url:\n",
    "\n",
    "            review_url = url\n",
    "            review_rep = requests.get(review_url)\n",
    "            review_response = TextResponse(review_rep.url, body=review_rep.text, encoding='utf-8')        \n",
    "\n",
    "            # Top100 상품마다의 상품평 개수\n",
    "            review_total_cnt = int(review_response.xpath('/html/body/div[2]/@data-review-total-count').extract()[0])\n",
    "\n",
    "            # Top100 상품마다 한 page의 상품평 개수\n",
    "            review_url_cnt = int(float(review_response.xpath('count(/html/body/article)').extract()[0]))\n",
    "\n",
    "            if review_url_cnt < 100:          \n",
    "                for i in range(1, review_url_cnt+1): # 한개의 review_url에서 100개를 훑고 그 다음 review_url로 넘어가면 됨\n",
    "                    item_nbr = product\n",
    "\n",
    "                    date = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[2]/text()'.format(i)).extract()[0]\n",
    "\n",
    "                    name = review_response.xpath('/html/body/article[{}]/div[1]/div[2]/span/text()'.format(i)).extract()[0][:-1]\n",
    "\n",
    "                    item_option_ls = review_response.xpath('/html/body/article[{}]/div[1]/div[4]/text()'.format(i)).extract()[0].split(\",\")\n",
    "                    if len(item_option_ls) == 1:\n",
    "                        item = item_option_ls[0]\n",
    "\n",
    "                    else:    \n",
    "                        item = item_option_ls[0]\n",
    "                        option = item_option_ls[1]\n",
    "\n",
    "                    if review_response.xpath('/html/body/article[{}]/div[3]/@class'.format(i)).extract()[0] == 'sdp-review__article__list__headline':\n",
    "                        re_title = review_response.xpath('/html/body/article[{}]/div[3]/text()'.format(i)).extract()\n",
    "                        review = review_response.xpath('/html/body/article[{}]/div[4]/div/text()'.format(i)).extract()\n",
    "\n",
    "                    else:\n",
    "                        re_title = ['.']\n",
    "                        review = review_response.xpath('/html/body/article[{}]/div[3]/div/text()'.format(i)).extract()\n",
    "\n",
    "                    rating = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[1]/div/@data-rating'.format(i)).extract()[0]\n",
    "\n",
    "                    df.loc[len(df)] = {'rating':rating, 'item_nbr':item_nbr, 'item':item, 'option':option, 'date':date, 'name':name, 're_title':re_title, 'review':review}\n",
    "\n",
    "            else:\n",
    "                for i in range(1, 101):\n",
    "                    item_nbr = product\n",
    "\n",
    "                    date = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[2]/text()'.format(i)).extract()[0]\n",
    "\n",
    "                    name = review_response.xpath('/html/body/article[{}]/div[1]/div[2]/span/text()'.format(i)).extract()[0][:-1]\n",
    "\n",
    "                    item_option_ls = review_response.xpath('/html/body/article[{}]/div[1]/div[4]/text()'.format(i)).extract()[0].split(\",\")\n",
    "                    if len(item_option_ls) == 1:\n",
    "                        item = item_option_ls[0]\n",
    "\n",
    "                    else:    \n",
    "                        item = item_option_ls[0]\n",
    "                        option = item_option_ls[1]\n",
    "\n",
    "                    if review_response.xpath('/html/body/article[{}]/div[3]/@class'.format(i)).extract()[0] == 'sdp-review__article__list__headline':\n",
    "                        re_title = review_response.xpath('/html/body/article[{}]/div[3]/text()'.format(i)).extract()\n",
    "                        review = review_response.xpath('/html/body/article[{}]/div[4]/div/text()'.format(i)).extract()\n",
    "\n",
    "                    else:\n",
    "                        re_title = ['.']\n",
    "                        review = review_response.xpath('/html/body/article[{}]/div[3]/div/text()'.format(i)).extract()\n",
    "\n",
    "                    rating = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[1]/div/@data-rating'.format(i)).extract()[0]\n",
    "\n",
    "                    df.loc[len(df)] = {'rating':rating, 'item_nbr':item_nbr, 'item':item, 'option':option, 'date':date, 'name':name, 're_title':re_title, 'review':review}\n",
    "\n",
    "    print(\"{}개 상품 중 review가 없는 상품 수 : {}\".format(item_count_end-item_count_start, no_review_cnt))\n",
    "    \n",
    "    \n",
    "    df['re_title_filtered'] = df['re_title'].apply(__re_title_filter)\n",
    "    df['review_filtered'] = df['review'].apply(__review_filter)\n",
    "    df['full_review'] = df['re_title_filtered']+df['review_filtered']\n",
    "    df['pos'] = df['full_review'].apply(kkma_pos)\n",
    "    df['pos_filtered'] = df['pos'].apply(__kkma_pos_filter)\n",
    "    df['rating_filtered'] = df['rating'].apply(__rating_filter)\n",
    "    \n",
    "    # 'pos_filtered' == 0인 데이터 삭제\n",
    "    idx = []\n",
    "    for i in range(len(df)):\n",
    "        if len(df['pos_filtered'][i][0]) == 0: # 리스트 안의 문자열의 길이가 0인지를 확인\n",
    "            idx.append(i)\n",
    "    df = df.drop(index=idx).reset_index()\n",
    "    \n",
    "    print(\"{}'s Top{} Review Total Count : {}\".format(keyword, item_count_end, top100_review_total_cnt))\n",
    "    print(\"{}'s Top{} Filtered Review Count : {}\".format(keyword, item_count_end, len(df)))\n",
    "    \n",
    "    df_fin = df[['rating', 'rating_filtered', 'item_nbr', 'item', 'option', 'date', 'name', 'full_review', 'pos', 'pos_filtered']]\n",
    "    \n",
    "    return df_fin\n",
    "\n",
    "def make_pos_voca(df_train, keyword, raworcsv='csv'):\n",
    "    \"\"\"\n",
    "    train 데이터에서 단어와 pos가 담긴 vocabulary 만들기\n",
    "    csv를 불러온 데이터의 경우 반드시 pos_new 컬럼이 존재해야함\n",
    "    \"\"\"\n",
    "    pos_voca = []\n",
    "    if raworcsv == 'csv':\n",
    "        for i in range(len(df_train)):\n",
    "            for ii in range(len(df_train[\"pos_new\"][i])):\n",
    "                if df_train[\"pos_new\"][i][ii] not in pos_voca:\n",
    "                    pos_voca.append(df_train[\"pos_new\"][i][ii])\n",
    "        pickle.dump(pos_voca, open(\"save_pos_voca_pkl/pos_voca_{}.pkl\".format(keyword), \"wb\"))\n",
    "        return pos_voca\n",
    "    else:\n",
    "        for i in range(len(df_train)):\n",
    "            for ii in range(len(df_train[\"pos\"][i])):\n",
    "                if df_train[\"pos\"][i][ii] not in pos_voca:\n",
    "                    pos_voca.append(df_train[\"pos\"][i][ii])\n",
    "        pickle.dump(pos_voca, open(\"save_pos_voca_pkl/pos_voca_{}.pkl\".format(keyword), \"wb\"))\n",
    "        return pos_voca\n",
    "\n",
    "def read_pos_voca(keyword):\n",
    "    pos_voca = pickle.load(open(\"save_pos_voca_pkl/pos_voca_{}.pkl\".format(keyword), \"rb\"))\n",
    "    return pos_voca\n",
    "    \n",
    "def test_overview(product):\n",
    "    \n",
    "    reveiw_cnt_url = 'http://www.coupang.com/vp/product/reviews?productId={}&page=1&size=100&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=2&ratingSummary=true'.format(product)\n",
    "    reveiw_cnt_rep = requests.get(reveiw_cnt_url)\n",
    "    reveiw_cnt_response = TextResponse(reveiw_cnt_rep.url, body=reveiw_cnt_rep.text, encoding='utf-8')\n",
    "    \n",
    "    item_name = reveiw_cnt_response.xpath('/html/body/article[1]/div[1]/div[4]/text()').extract()[0].split(',')[0]\n",
    "    review_total_cnt = int(reveiw_cnt_response.xpath('/html/body/div[2]/@data-review-total-count').extract()[0])\n",
    "  \n",
    "    return item_name, review_total_cnt\n",
    "\n",
    "def df_test_len(df_test):\n",
    "    return len(df_test)\n",
    "\n",
    "def make_df_test(product):\n",
    "    \n",
    "    # 상품마다의 링크를 불러오기에 앞서 아이템 Top36 리스트 불러오기\n",
    "#     products = json.loads(response.xpath('//*[@id=\"productList\"]/@data-products').extract()[0])['indexes'][:36]\n",
    "\n",
    "    df = pd.DataFrame(columns=['rating', \"item_nbr\", \"item\", \"option\", \"date\", \"name\", \"re_title\", 'review']) \n",
    "\n",
    "    reveiw_cnt_url = 'http://www.coupang.com/vp/product/reviews?productId={}&page=1&size=100&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=2&ratingSummary=true'.format(product)\n",
    "    reveiw_cnt_rep = requests.get(reveiw_cnt_url)\n",
    "    reveiw_cnt_response = TextResponse(reveiw_cnt_rep.url, body=reveiw_cnt_rep.text, encoding='utf-8')\n",
    "    \n",
    "    item_name = reveiw_cnt_response.xpath('/html/body/article[1]/div[1]/div[4]/text()').extract()[0].split(',')[0]\n",
    "    review_total_cnt = int(reveiw_cnt_response.xpath('/html/body/div[2]/@data-review-total-count').extract()[0])\n",
    "\n",
    "    def make_url(product, review_total_cnt):\n",
    "        page_count = (review_total_cnt//100)+1\n",
    "        review_urls = []\n",
    "        for page in range(1, page_count+1):\n",
    "            review_urls.append('http://www.coupang.com/vp/product/reviews?productId={}&page={}&size=100&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=2&ratingSummary=true'.format(product, page))\n",
    "            # size는 100이 최대로 설정되어 있음\n",
    "        return review_urls\n",
    "\n",
    "    review_url = make_url(product, review_total_cnt) # 리스트로 반환됨\n",
    "\n",
    "    for url in review_url:\n",
    "\n",
    "        review_url = url\n",
    "        review_rep = requests.get(review_url)\n",
    "        review_response = TextResponse(review_rep.url, body=review_rep.text, encoding='utf-8')        \n",
    "\n",
    "        # Top36 상품마다의 상품평 개수\n",
    "        review_total_cnt = int(review_response.xpath('/html/body/div[2]/@data-review-total-count').extract()[0])\n",
    "\n",
    "        # Top36 상품마다 한 page의 상품평 개수\n",
    "        review_url_cnt = int(float(review_response.xpath('count(/html/body/article)').extract()[0]))\n",
    "\n",
    "        if review_url_cnt < 100:          \n",
    "            for i in range(1, review_url_cnt+1): # 한개의 review_url에서 100개를 훑고 그 다음 review_url로 넘어가면 됨\n",
    "                item_nbr = product\n",
    "\n",
    "                date = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[2]/text()'.format(i)).extract()[0]\n",
    "\n",
    "                name = review_response.xpath('/html/body/article[{}]/div[1]/div[2]/span/text()'.format(i)).extract()[0][:-1]\n",
    "\n",
    "                item_option_ls = review_response.xpath('/html/body/article[{}]/div[1]/div[4]/text()'.format(i)).extract()[0].split(\",\")\n",
    "                if len(item_option_ls) == 1:\n",
    "                    item = item_option_ls[0]\n",
    "\n",
    "                else:    \n",
    "                    item = item_option_ls[0]\n",
    "                    option = item_option_ls[1]\n",
    "\n",
    "                if review_response.xpath('/html/body/article[{}]/div[3]/@class'.format(i)).extract()[0] == 'sdp-review__article__list__headline':\n",
    "                    re_title = review_response.xpath('/html/body/article[{}]/div[3]/text()'.format(i)).extract()\n",
    "                    review = review_response.xpath('/html/body/article[{}]/div[4]/div/text()'.format(i)).extract()\n",
    "\n",
    "                else:\n",
    "                    re_title = ['.']\n",
    "                    review = review_response.xpath('/html/body/article[{}]/div[3]/div/text()'.format(i)).extract()\n",
    "\n",
    "                rating = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[1]/div/@data-rating'.format(i)).extract()[0]\n",
    "\n",
    "                df.loc[len(df)] = {'rating':rating, 'item_nbr':item_nbr, 'item':item, 'option':option, 'date':date, 'name':name, 're_title':re_title, 'review':review}\n",
    "\n",
    "        else:\n",
    "            for i in range(1, 101):\n",
    "                item_nbr = product\n",
    "\n",
    "                date = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[2]/text()'.format(i)).extract()[0]\n",
    "\n",
    "                name = review_response.xpath('/html/body/article[{}]/div[1]/div[2]/span/text()'.format(i)).extract()[0][:-1]\n",
    "\n",
    "                item_option_ls = review_response.xpath('/html/body/article[{}]/div[1]/div[4]/text()'.format(i)).extract()[0].split(\",\")\n",
    "                if len(item_option_ls) == 1:\n",
    "                    item = item_option_ls[0]\n",
    "\n",
    "                else:    \n",
    "                    item = item_option_ls[0]\n",
    "                    option = item_option_ls[1]\n",
    "\n",
    "                if review_response.xpath('/html/body/article[{}]/div[3]/@class'.format(i)).extract()[0] == 'sdp-review__article__list__headline':\n",
    "                    re_title = review_response.xpath('/html/body/article[{}]/div[3]/text()'.format(i)).extract()\n",
    "                    review = review_response.xpath('/html/body/article[{}]/div[4]/div/text()'.format(i)).extract()\n",
    "\n",
    "                else:\n",
    "                    re_title = ['.']\n",
    "                    review = review_response.xpath('/html/body/article[{}]/div[3]/div/text()'.format(i)).extract()\n",
    "\n",
    "                rating = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[1]/div/@data-rating'.format(i)).extract()[0]\n",
    "\n",
    "                df.loc[len(df)] = {'rating':rating, 'item_nbr':item_nbr, 'item':item, 'option':option, 'date':date, 'name':name, 're_title':re_title, 'review':review}\n",
    "    \n",
    "    df['re_title_filtered'] = df['re_title'].apply(__re_title_filter)\n",
    "    df['review_filtered'] = df['review'].apply(__review_filter)\n",
    "    df['full_review'] = df['re_title_filtered']+df['review_filtered']\n",
    "    df['pos'] = df['full_review'].apply(kkma_pos)\n",
    "    df['pos_filtered'] = df['pos'].apply(__kkma_pos_filter)\n",
    "    df['rating_filtered'] = df['rating'].apply(__rating_filter)\n",
    "    \n",
    "    # 'pos_filtered' == 0인 데이터 삭제\n",
    "    idx = []\n",
    "    for i in range(len(df)):\n",
    "        if len(df['pos_filtered'][i][0]) == 0: # 리스트 안의 문자열의 길이가 0인지를 확인\n",
    "            idx.append(i)\n",
    "    df = df.drop(index=idx).reset_index()\n",
    "    \n",
    "    print(\"{}'s Review Total Count : {}\".format(item_name, review_total_cnt))\n",
    "    print(\"{}'s Filtered Review Count : {}\".format(item_name, len(df)))\n",
    "    \n",
    "    df_fin = df[['rating', 'rating_filtered', 'item_nbr', 'item', 'option', 'date', 'name', 'full_review', 'pos', 'pos_filtered']]\n",
    "    \n",
    "    return df_fin\n",
    "\n",
    "def __re_title_filter(a):\n",
    "    for i in range(len(a[0].split('\\n'))):\n",
    "        if len(a[0].split('\\n')[i].strip()) != 0:\n",
    "            return a[0].split('\\n')[i].strip()\n",
    "        else:\n",
    "            return '.'\n",
    "\n",
    "def __review_filter(a):\n",
    "    s = ''\n",
    "    for i in range(len(a)):\n",
    "        for ii in range(len(a[i].split('\\n'))):\n",
    "            if a[i].split('\\n')[ii].strip() != 0:\n",
    "                s += a[i].split('\\n')[ii].strip() + ' '\n",
    "    return s\n",
    "\n",
    "def kkma_pos(a):\n",
    "    kkma = Kkma()\n",
    "    return kkma.pos(a)\n",
    "\n",
    "def __kkma_pos_filter(a):\n",
    "    \"\"\"\n",
    "    df['pos']를 받아 품사 필터링을 거쳐 해당 키워드 리스트 반환\n",
    "    \"\"\"\n",
    "    pos_ls = ['NNG','NNP','VA','UN','XR','MAG','ECE']\n",
    "    ls = []\n",
    "    s = \"\"\n",
    "    for i in range(len(a)):\n",
    "        #NNG(보통 명사), NNP(고유 명사), VA(형용사), XR(어근), MAG(일반 부사), UN(명사추정범주)\n",
    "        if a[i][1] in pos_ls:\n",
    "            s += a[i][0] + ','\n",
    "    ls.append(s)\n",
    "    return ls\n",
    "\n",
    "def __rating_filter(a):\n",
    "    if a == '3' or a == '4' or a == '5':\n",
    "        return 1\n",
    "        # 긍정\n",
    "    else:\n",
    "        return 0\n",
    "        # 부정\n",
    "        \n",
    "def Vectorizer_train(df_train, keyword, stop_words=None):\n",
    "    \"\"\"\n",
    "    df_train의 'pos_filtered' column을 받아 vectorized df를 생성해주는 함수\n",
    "    \"\"\"\n",
    "    train_corpus = []\n",
    "    for i in range(len(df_train['pos_filtered'])):\n",
    "        train_corpus.append(df_train['pos_filtered'][i][0])\n",
    "\n",
    "    vect = CountVectorizer(token_pattern=r\"\\b\\w+\\b\", stop_words=stop_words) # 한 글자도 corpus에 포함될 수 있게 해주는 정규표현식\n",
    "    vect.fit(train_corpus)\n",
    "    \n",
    "    pickle.dump(vect, open(\"save_vect_pkl/vect_{}.pkl\".format(keyword), \"wb\"))\n",
    "\n",
    "    vect_ls = []\n",
    "    for i in range(len(df_train)):\n",
    "        vect_ls.append(vect.transform(df_train['pos_filtered'][i]).toarray()[0])\n",
    "        # 리스트안의 리스트로 반환되기 때문에 vect_ls 안에 append하기 전에 [0]로 꺼내줌\n",
    "    \n",
    "    # 문자열 하나를 문장으로 간주\n",
    "    # corpus에는 여러 문장이 하나의 리스트 안의 문자열 요소로 들어가야 하고, ['an apple is red', 'the boy is young']\n",
    "    # transform할때는 한 문장이 하나의 리스트 안의 문자열 요소로 들어가야 함 ['an apple is red']\n",
    "    \n",
    "    df_vec = pd.DataFrame(vect_ls)\n",
    "    \n",
    "    return df_vec\n",
    "\n",
    "def Vectorizer_test(df_input, keyword):\n",
    "    \"\"\"\n",
    "    df_input의 'pos_filtered' column을 받아 vectorized df를 생성해주는 함수\n",
    "    df와 vect.vocabulary_를 반환\n",
    "    \"\"\"\n",
    "    vect = pickle.load(open(\"save_vect_pkl/vect_{}.pkl\".format(keyword), \"rb\"))\n",
    "    \n",
    "    vect_ls = []\n",
    "    for i in range(len(df_input)):\n",
    "        vect_ls.append(vect.transform(df_input['pos_filtered'][i]).toarray()[0])\n",
    "        # 리스트안의 리스트로 반환되기 때문에 vect_ls 안에 append하기 전에 [0]로 꺼내줌\n",
    "    \n",
    "    # 문자열 하나를 문장으로 간주\n",
    "    # corpus에는 여러 문장이 하나의 리스트 안의 문자열 요소로 들어가야 하고, ['an apple is red', 'the boy is young']\n",
    "    # transform할때는 한 문장이 하나의 리스트 안의 문자열 요소로 들어가야 함 ['an apple is red']\n",
    "    \n",
    "    df_vec = pd.DataFrame(vect_ls)\n",
    "\n",
    "    return df_vec, vect.vocabulary_ \n",
    "    \n",
    "def top_word_negative(X_test, y_test_pred, df_test, pos_voca, voca, word_cnt=20):\n",
    "    \"\"\"\n",
    "    pos_voca에는 단어와 pos 정보가 담겨있고\n",
    "    voca에는 단어와 vect모델 안에서의 단어별 index 정보가 담겨있다\n",
    "    \"\"\"\n",
    "    y_test_pred = pd.DataFrame(y_test_pred, columns=['prediction'])\n",
    "    pred_n_test = pd.concat([y_test_pred, X_test], axis=1)\n",
    "    top_word = pd.DataFrame(pred_n_test[pred_n_test['prediction']==0].sum().sort_values(ascending=False), columns=['count']).reset_index()\n",
    "    # reset_index()하면 원래 series에서 갖고있던 index를 value로 만들어줌\n",
    "    \n",
    "    top_word = top_word[top_word['count'] > 0]\n",
    "\n",
    "    def match_word(a):\n",
    "        for key, value in voca.items():\n",
    "            if value == a:\n",
    "                return key\n",
    "            \n",
    "    def real_pos(a):\n",
    "        for i in range(len(pos_voca)):\n",
    "            if a == pos_voca[i][0]:\n",
    "                return pos_voca[i][1]        \n",
    "    \n",
    "    top_word['word'] = top_word['index'].apply(match_word)\n",
    "    top_word['pos'] = top_word['word'].apply(real_pos)\n",
    "    \n",
    "    top_word = top_word[top_word['pos'].isin(['NNG','NNP', 'XR', 'UN'])].reset_index()[:word_cnt]\n",
    "    \n",
    "    def review_return(a):\n",
    "        idx_ls = list(pred_n_test[(pred_n_test['prediction']==0)&(pred_n_test[a] >= 1)].index)\n",
    "        return list(df_test[df_test.index.isin(idx_ls)]['full_review'].values)\n",
    "        \n",
    "    top_word['review'] = top_word['index'].apply(review_return)\n",
    "    \n",
    "    return top_word[['index','word', 'pos', 'count', 'review']]\n",
    "\n",
    "\n",
    "def top_word_positive(X_test, y_test_pred, df_test, pos_voca, voca, word_cnt=20):\n",
    "    \"\"\"\n",
    "    pos_voca에는 단어와 pos 정보가 담겨있고\n",
    "    voca에는 단어와 vect모델 안에서의 단어별 index 정보가 담겨있다\n",
    "    \"\"\"\n",
    "    y_test_pred = pd.DataFrame(y_test_pred, columns=['prediction'])\n",
    "    pred_n_test = pd.concat([y_test_pred, X_test], axis=1)\n",
    "    top_word = pd.DataFrame(pred_n_test[pred_n_test['prediction']==1].sum().sort_values(ascending=False), columns=['count']).reset_index()\n",
    "    # reset_index()하면 원래 series에서 갖고있던 index를 value로 만들어줌\n",
    "    \n",
    "    top_word_ = top_word[top_word['index'] != 'prediction'].reset_index(drop=True)\n",
    "    # prediction이 1이기 때문에 count값이 정수로 생기고, 그 row를 삭제해줌\n",
    "    top_word = top_word[top_word['count'] > 0]\n",
    "\n",
    "    def match_word(a):\n",
    "        for key, value in voca.items():\n",
    "            if value == a:\n",
    "                return key\n",
    "            \n",
    "    def real_pos(a):\n",
    "        for i in range(len(pos_voca)):\n",
    "            if a == pos_voca[i][0]:\n",
    "                return pos_voca[i][1]        \n",
    "    \n",
    "    top_word['word'] = top_word['index'].apply(match_word)\n",
    "    top_word['pos'] = top_word['word'].apply(real_pos)\n",
    "    \n",
    "    top_word = top_word[top_word['pos'].isin(['NNG','NNP', 'XR', 'UN'])].reset_index()[:word_cnt]\n",
    "    \n",
    "    def review_return(a):\n",
    "        idx_ls = list(pred_n_test[(pred_n_test['prediction']==1)&(pred_n_test[a] >= 1)].index)\n",
    "        return list(df_test[df_test.index.isin(idx_ls)]['full_review'].values)\n",
    "        \n",
    "    top_word['review'] = top_word['index'].apply(review_return)\n",
    "    \n",
    "    return top_word[['index','word', 'pos', 'count', 'review']]\n",
    "\n",
    "def top_word_word(df_top_word):\n",
    "    return list(df_top_word['word'].values)\n",
    "\n",
    "def top_word_count(df_top_word):\n",
    "    # jsonify에서 np.int는 오류나므로 int로 형변환해주어야 함\n",
    "    return [int(val) for val in df_top_word['count'].values]\n",
    "\n",
    "def top_word_review(df_top_word):\n",
    "    return list(df_top_word['review'].values)    \n",
    "    \n",
    "def neg_or_pos(y_test_pred):\n",
    "    \"\"\"\n",
    "    y_test_pred를 받아서 negative 댓글 개수와 positive 댓글 개수를 int로 반환\n",
    "    \"\"\"\n",
    "    y_test_pred = pd.DataFrame(y_test_pred, columns=['prediction'])\n",
    "    neg_or_pos = y_test_pred.groupby(by='prediction').size().reset_index(name='count')\n",
    "    neg = int(list(neg_or_pos[neg_or_pos['prediction']==0]['count'].values)[0])\n",
    "    pos = int(list(neg_or_pos[neg_or_pos['prediction']==1]['count'].values)[0])\n",
    "    return neg, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile function_fin.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from scrapy.http import TextResponse\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Kkma\n",
    "import pickle\n",
    "\n",
    "def review_cnt_check(keyword, item_count_start=0, item_count_end=100):\n",
    "\n",
    "    search_url = \"http://www.coupang.com/np/search?q={}&isPriceRange=false&page=1&sorter=scoreDesc&listSize=100\".format(keyword)\n",
    "    rep = requests.get(search_url)\n",
    "    response = TextResponse(rep.url, body=rep.text, encoding='utf-8')\n",
    "\n",
    "    # 상품마다의 링크를 불러오기에 앞서 아이템 Top100 리스트 불러오기\n",
    "    products = json.loads(response.xpath('//*[@id=\"productList\"]/@data-products').extract()[0])['indexes'][item_count_start:item_count_end]\n",
    "    \n",
    "    review_total_cnt = 0\n",
    "    \n",
    "    for idx, product in enumerate(products):\n",
    "        \n",
    "        # Top100 상품마다의 상품평 개수(나중에 불러오는 정보라 상품링크 안에서는 xpath로 바로 가져올 수 없음)\n",
    "        try:\n",
    "            review_count = int(response.xpath('//*[@id=\"{}\"]/a/dl/dd/div/div[4]/div[2]/span[2]/text()'.format(product)).extract()[0].strip(\"()\"))\n",
    "            review_total_cnt += review_count\n",
    "            print('{}번째 item {}의 review 수 : {}'.format(idx, product, review_count))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('No reviews')\n",
    "            \n",
    "    print('{}번째부터 {}번째 item의 총 review 수 : {}'.format(item_count_start, item_count_end-1, review_total_cnt))\n",
    "\n",
    "def make_df_train(keyword, item_count_start=0, item_count_end=100):\n",
    "    \n",
    "    search_url = \"http://www.coupang.com/np/search?q={}&isPriceRange=false&page=1&sorter=scoreDesc&listSize=100\".format(keyword)\n",
    "    rep = requests.get(search_url)\n",
    "    response = TextResponse(rep.url, body=rep.text, encoding='utf-8')\n",
    "\n",
    "    # 상품마다의 링크를 불러오기에 앞서 아이템 Top100 리스트 불러오기\n",
    "    products = json.loads(response.xpath('//*[@id=\"productList\"]/@data-products').extract()[0])['indexes'][item_count_start:item_count_end]\n",
    "    products = list(set(products))\n",
    "    print(\"총 {}개의 상품에서 중복제거 후 {}개의 상품 크롤링\".format(item_count_end-item_count_start,len(products)))\n",
    "    \n",
    "    df = pd.DataFrame(columns=['rating', \"item_nbr\", \"item\", \"option\", \"date\", \"name\", \"re_title\", 'review']) \n",
    "\n",
    "    top100_review_total_cnt = 0\n",
    "    review_count = 0\n",
    "    no_review_cnt = 0\n",
    "    \n",
    "    for product in products:\n",
    "        \n",
    "        # Top100 상품마다의 상품평 개수(나중에 불러오는 정보라 상품링크 안에서는 xpath로 바로 가져올 수 없음)\n",
    "        try:\n",
    "            review_count = int(response.xpath('//*[@id=\"{}\"]/a/dl/dd/div/div[4]/div[2]/span[2]/text()'.format(product)).extract()[0].strip(\"()\"))\n",
    "            top100_review_total_cnt += review_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            no_review_cnt += 1\n",
    "        \n",
    "        # product for문 안에서 수행하는 코드    \n",
    "        def make_url(product, review_count):\n",
    "            page_count = (review_count//100)+1\n",
    "            review_urls = []\n",
    "            for page in range(1, page_count+1):\n",
    "                review_urls.append('http://www.coupang.com/vp/product/reviews?productId={}&page={}&size=100&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=2&ratingSummary=true'.format(product, page))\n",
    "                # size는 100이 최대로 설정되어 있음\n",
    "            return review_urls\n",
    "\n",
    "\n",
    "        # Top100 상품마다의 크롤링할 url(리뷰 크롤링은 '상품평 보기' 클릭 후 나타나는 reviews Request URL에서 해야함)\n",
    "#         review_urls[product] = make_url(product, review_count)\n",
    "        review_url = make_url(product, review_count) # 리스트로 반환됨\n",
    "\n",
    "        for url in review_url:\n",
    "\n",
    "            review_url = url\n",
    "            review_rep = requests.get(review_url)\n",
    "            review_response = TextResponse(review_rep.url, body=review_rep.text, encoding='utf-8')        \n",
    "\n",
    "            # Top100 상품마다의 상품평 개수\n",
    "            review_total_cnt = int(review_response.xpath('/html/body/div[2]/@data-review-total-count').extract()[0])\n",
    "\n",
    "            # Top100 상품마다 한 page의 상품평 개수\n",
    "            review_url_cnt = int(float(review_response.xpath('count(/html/body/article)').extract()[0]))\n",
    "\n",
    "            if review_url_cnt < 100:          \n",
    "                for i in range(1, review_url_cnt+1): # 한개의 review_url에서 100개를 훑고 그 다음 review_url로 넘어가면 됨\n",
    "                    item_nbr = product\n",
    "\n",
    "                    date = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[2]/text()'.format(i)).extract()[0]\n",
    "\n",
    "                    name = review_response.xpath('/html/body/article[{}]/div[1]/div[2]/span/text()'.format(i)).extract()[0][:-1]\n",
    "\n",
    "                    item_option_ls = review_response.xpath('/html/body/article[{}]/div[1]/div[4]/text()'.format(i)).extract()[0].split(\",\")\n",
    "                    if len(item_option_ls) == 1:\n",
    "                        item = item_option_ls[0]\n",
    "\n",
    "                    else:    \n",
    "                        item = item_option_ls[0]\n",
    "                        option = item_option_ls[1]\n",
    "\n",
    "                    if review_response.xpath('/html/body/article[{}]/div[3]/@class'.format(i)).extract()[0] == 'sdp-review__article__list__headline':\n",
    "                        re_title = review_response.xpath('/html/body/article[{}]/div[3]/text()'.format(i)).extract()\n",
    "                        review = review_response.xpath('/html/body/article[{}]/div[4]/div/text()'.format(i)).extract()\n",
    "\n",
    "                    else:\n",
    "                        re_title = ['.']\n",
    "                        review = review_response.xpath('/html/body/article[{}]/div[3]/div/text()'.format(i)).extract()\n",
    "\n",
    "                    rating = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[1]/div/@data-rating'.format(i)).extract()[0]\n",
    "\n",
    "                    df.loc[len(df)] = {'rating':rating, 'item_nbr':item_nbr, 'item':item, 'option':option, 'date':date, 'name':name, 're_title':re_title, 'review':review}\n",
    "\n",
    "            else:\n",
    "                for i in range(1, 101):\n",
    "                    item_nbr = product\n",
    "\n",
    "                    date = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[2]/text()'.format(i)).extract()[0]\n",
    "\n",
    "                    name = review_response.xpath('/html/body/article[{}]/div[1]/div[2]/span/text()'.format(i)).extract()[0][:-1]\n",
    "\n",
    "                    item_option_ls = review_response.xpath('/html/body/article[{}]/div[1]/div[4]/text()'.format(i)).extract()[0].split(\",\")\n",
    "                    if len(item_option_ls) == 1:\n",
    "                        item = item_option_ls[0]\n",
    "\n",
    "                    else:    \n",
    "                        item = item_option_ls[0]\n",
    "                        option = item_option_ls[1]\n",
    "\n",
    "                    if review_response.xpath('/html/body/article[{}]/div[3]/@class'.format(i)).extract()[0] == 'sdp-review__article__list__headline':\n",
    "                        re_title = review_response.xpath('/html/body/article[{}]/div[3]/text()'.format(i)).extract()\n",
    "                        review = review_response.xpath('/html/body/article[{}]/div[4]/div/text()'.format(i)).extract()\n",
    "\n",
    "                    else:\n",
    "                        re_title = ['.']\n",
    "                        review = review_response.xpath('/html/body/article[{}]/div[3]/div/text()'.format(i)).extract()\n",
    "\n",
    "                    rating = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[1]/div/@data-rating'.format(i)).extract()[0]\n",
    "\n",
    "                    df.loc[len(df)] = {'rating':rating, 'item_nbr':item_nbr, 'item':item, 'option':option, 'date':date, 'name':name, 're_title':re_title, 'review':review}\n",
    "\n",
    "    print(\"{}개 상품 중 review가 없는 상품 수 : {}\".format(item_count_end-item_count_start, no_review_cnt))\n",
    "    \n",
    "    \n",
    "    df['re_title_filtered'] = df['re_title'].apply(__re_title_filter)\n",
    "    df['review_filtered'] = df['review'].apply(__review_filter)\n",
    "    df['full_review'] = df['re_title_filtered']+df['review_filtered']\n",
    "    df['pos'] = df['full_review'].apply(kkma_pos)\n",
    "    df['pos_filtered'] = df['pos'].apply(__kkma_pos_filter)\n",
    "    df['rating_filtered'] = df['rating'].apply(__rating_filter)\n",
    "    \n",
    "    # 'pos_filtered' == 0인 데이터 삭제\n",
    "    idx = []\n",
    "    for i in range(len(df)):\n",
    "        if len(df['pos_filtered'][i][0]) == 0: # 리스트 안의 문자열의 길이가 0인지를 확인\n",
    "            idx.append(i)\n",
    "    df = df.drop(index=idx).reset_index()\n",
    "    \n",
    "    print(\"{}'s Top{} Review Total Count : {}\".format(keyword, item_count_end, top100_review_total_cnt))\n",
    "    print(\"{}'s Top{} Filtered Review Count : {}\".format(keyword, item_count_end, len(df)))\n",
    "    \n",
    "    df_fin = df[['rating', 'rating_filtered', 'item_nbr', 'item', 'option', 'date', 'name', 'full_review', 'pos', 'pos_filtered']]\n",
    "    \n",
    "    return df_fin\n",
    "\n",
    "def make_pos_voca(df_train, keyword, raworcsv='csv'):\n",
    "    \"\"\"\n",
    "    train 데이터에서 단어와 pos가 담긴 vocabulary 만들기\n",
    "    csv를 불러온 데이터의 경우 반드시 pos_new 컬럼이 존재해야함\n",
    "    \"\"\"\n",
    "    pos_voca = []\n",
    "    if raworcsv == 'csv':\n",
    "        for i in range(len(df_train)):\n",
    "            for ii in range(len(df_train[\"pos_new\"][i])):\n",
    "                if df_train[\"pos_new\"][i][ii] not in pos_voca:\n",
    "                    pos_voca.append(df_train[\"pos_new\"][i][ii])\n",
    "        pickle.dump(pos_voca, open(\"save_pos_voca_pkl/pos_voca_{}.pkl\".format(keyword), \"wb\"))\n",
    "        return pos_voca\n",
    "    else:\n",
    "        for i in range(len(df_train)):\n",
    "            for ii in range(len(df_train[\"pos\"][i])):\n",
    "                if df_train[\"pos\"][i][ii] not in pos_voca:\n",
    "                    pos_voca.append(df_train[\"pos\"][i][ii])\n",
    "        pickle.dump(pos_voca, open(\"save_pos_voca_pkl/pos_voca_{}.pkl\".format(keyword), \"wb\"))\n",
    "        return pos_voca\n",
    "\n",
    "def read_pos_voca(keyword):\n",
    "    pos_voca = pickle.load(open(\"save_pos_voca_pkl/pos_voca_{}.pkl\".format(keyword), \"rb\"))\n",
    "    return pos_voca\n",
    "    \n",
    "def test_overview(product):\n",
    "    \n",
    "    reveiw_cnt_url = 'http://www.coupang.com/vp/product/reviews?productId={}&page=1&size=100&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=2&ratingSummary=true'.format(product)\n",
    "    reveiw_cnt_rep = requests.get(reveiw_cnt_url)\n",
    "    reveiw_cnt_response = TextResponse(reveiw_cnt_rep.url, body=reveiw_cnt_rep.text, encoding='utf-8')\n",
    "    \n",
    "    item_name = reveiw_cnt_response.xpath('/html/body/article[1]/div[1]/div[4]/text()').extract()[0].split(',')[0]\n",
    "    review_total_cnt = int(reveiw_cnt_response.xpath('/html/body/div[2]/@data-review-total-count').extract()[0])\n",
    "  \n",
    "    return item_name, review_total_cnt\n",
    "\n",
    "def df_test_len(df_test):\n",
    "    return len(df_test)\n",
    "\n",
    "def make_df_test(product):\n",
    "    \n",
    "    # 상품마다의 링크를 불러오기에 앞서 아이템 Top36 리스트 불러오기\n",
    "#     products = json.loads(response.xpath('//*[@id=\"productList\"]/@data-products').extract()[0])['indexes'][:36]\n",
    "\n",
    "    df = pd.DataFrame(columns=['rating', \"item_nbr\", \"item\", \"option\", \"date\", \"name\", \"re_title\", 'review']) \n",
    "\n",
    "    reveiw_cnt_url = 'http://www.coupang.com/vp/product/reviews?productId={}&page=1&size=100&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=2&ratingSummary=true'.format(product)\n",
    "    reveiw_cnt_rep = requests.get(reveiw_cnt_url)\n",
    "    reveiw_cnt_response = TextResponse(reveiw_cnt_rep.url, body=reveiw_cnt_rep.text, encoding='utf-8')\n",
    "    \n",
    "    item_name = reveiw_cnt_response.xpath('/html/body/article[1]/div[1]/div[4]/text()').extract()[0].split(',')[0]\n",
    "    review_total_cnt = int(reveiw_cnt_response.xpath('/html/body/div[2]/@data-review-total-count').extract()[0])\n",
    "\n",
    "    def make_url(product, review_total_cnt):\n",
    "        page_count = (review_total_cnt//100)+1\n",
    "        review_urls = []\n",
    "        for page in range(1, page_count+1):\n",
    "            review_urls.append('http://www.coupang.com/vp/product/reviews?productId={}&page={}&size=100&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=2&ratingSummary=true'.format(product, page))\n",
    "            # size는 100이 최대로 설정되어 있음\n",
    "        return review_urls\n",
    "\n",
    "    review_url = make_url(product, review_total_cnt) # 리스트로 반환됨\n",
    "\n",
    "    for url in review_url:\n",
    "\n",
    "        review_url = url\n",
    "        review_rep = requests.get(review_url)\n",
    "        review_response = TextResponse(review_rep.url, body=review_rep.text, encoding='utf-8')        \n",
    "\n",
    "        # Top36 상품마다의 상품평 개수\n",
    "        review_total_cnt = int(review_response.xpath('/html/body/div[2]/@data-review-total-count').extract()[0])\n",
    "\n",
    "        # Top36 상품마다 한 page의 상품평 개수\n",
    "        review_url_cnt = int(float(review_response.xpath('count(/html/body/article)').extract()[0]))\n",
    "\n",
    "        if review_url_cnt < 100:          \n",
    "            for i in range(1, review_url_cnt+1): # 한개의 review_url에서 100개를 훑고 그 다음 review_url로 넘어가면 됨\n",
    "                item_nbr = product\n",
    "\n",
    "                date = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[2]/text()'.format(i)).extract()[0]\n",
    "\n",
    "                name = review_response.xpath('/html/body/article[{}]/div[1]/div[2]/span/text()'.format(i)).extract()[0][:-1]\n",
    "\n",
    "                item_option_ls = review_response.xpath('/html/body/article[{}]/div[1]/div[4]/text()'.format(i)).extract()[0].split(\",\")\n",
    "                if len(item_option_ls) == 1:\n",
    "                    item = item_option_ls[0]\n",
    "\n",
    "                else:    \n",
    "                    item = item_option_ls[0]\n",
    "                    option = item_option_ls[1]\n",
    "\n",
    "                if review_response.xpath('/html/body/article[{}]/div[3]/@class'.format(i)).extract()[0] == 'sdp-review__article__list__headline':\n",
    "                    re_title = review_response.xpath('/html/body/article[{}]/div[3]/text()'.format(i)).extract()\n",
    "                    review = review_response.xpath('/html/body/article[{}]/div[4]/div/text()'.format(i)).extract()\n",
    "\n",
    "                else:\n",
    "                    re_title = ['.']\n",
    "                    review = review_response.xpath('/html/body/article[{}]/div[3]/div/text()'.format(i)).extract()\n",
    "\n",
    "                rating = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[1]/div/@data-rating'.format(i)).extract()[0]\n",
    "\n",
    "                df.loc[len(df)] = {'rating':rating, 'item_nbr':item_nbr, 'item':item, 'option':option, 'date':date, 'name':name, 're_title':re_title, 'review':review}\n",
    "\n",
    "        else:\n",
    "            for i in range(1, 101):\n",
    "                item_nbr = product\n",
    "\n",
    "                date = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[2]/text()'.format(i)).extract()[0]\n",
    "\n",
    "                name = review_response.xpath('/html/body/article[{}]/div[1]/div[2]/span/text()'.format(i)).extract()[0][:-1]\n",
    "\n",
    "                item_option_ls = review_response.xpath('/html/body/article[{}]/div[1]/div[4]/text()'.format(i)).extract()[0].split(\",\")\n",
    "                if len(item_option_ls) == 1:\n",
    "                    item = item_option_ls[0]\n",
    "\n",
    "                else:    \n",
    "                    item = item_option_ls[0]\n",
    "                    option = item_option_ls[1]\n",
    "\n",
    "                if review_response.xpath('/html/body/article[{}]/div[3]/@class'.format(i)).extract()[0] == 'sdp-review__article__list__headline':\n",
    "                    re_title = review_response.xpath('/html/body/article[{}]/div[3]/text()'.format(i)).extract()\n",
    "                    review = review_response.xpath('/html/body/article[{}]/div[4]/div/text()'.format(i)).extract()\n",
    "\n",
    "                else:\n",
    "                    re_title = ['.']\n",
    "                    review = review_response.xpath('/html/body/article[{}]/div[3]/div/text()'.format(i)).extract()\n",
    "\n",
    "                rating = review_response.xpath('/html/body/article[{}]/div[1]/div[3]/div[1]/div/@data-rating'.format(i)).extract()[0]\n",
    "\n",
    "                df.loc[len(df)] = {'rating':rating, 'item_nbr':item_nbr, 'item':item, 'option':option, 'date':date, 'name':name, 're_title':re_title, 'review':review}\n",
    "    \n",
    "    df['re_title_filtered'] = df['re_title'].apply(__re_title_filter)\n",
    "    df['review_filtered'] = df['review'].apply(__review_filter)\n",
    "    df['full_review'] = df['re_title_filtered']+df['review_filtered']\n",
    "    df['pos'] = df['full_review'].apply(kkma_pos)\n",
    "    df['pos_filtered'] = df['pos'].apply(__kkma_pos_filter)\n",
    "    df['rating_filtered'] = df['rating'].apply(__rating_filter)\n",
    "    \n",
    "    # 'pos_filtered' == 0인 데이터 삭제\n",
    "    idx = []\n",
    "    for i in range(len(df)):\n",
    "        if len(df['pos_filtered'][i][0]) == 0: # 리스트 안의 문자열의 길이가 0인지를 확인\n",
    "            idx.append(i)\n",
    "    df = df.drop(index=idx).reset_index()\n",
    "    \n",
    "    print(\"{}'s Review Total Count : {}\".format(item_name, review_total_cnt))\n",
    "    print(\"{}'s Filtered Review Count : {}\".format(item_name, len(df)))\n",
    "    \n",
    "    df_fin = df[['rating', 'rating_filtered', 'item_nbr', 'item', 'option', 'date', 'name', 'full_review', 'pos', 'pos_filtered']]\n",
    "    \n",
    "    return df_fin\n",
    "\n",
    "def __re_title_filter(a):\n",
    "    for i in range(len(a[0].split('\\n'))):\n",
    "        if len(a[0].split('\\n')[i].strip()) != 0:\n",
    "            return a[0].split('\\n')[i].strip()\n",
    "        else:\n",
    "            return '.'\n",
    "\n",
    "def __review_filter(a):\n",
    "    s = ''\n",
    "    for i in range(len(a)):\n",
    "        for ii in range(len(a[i].split('\\n'))):\n",
    "            if a[i].split('\\n')[ii].strip() != 0:\n",
    "                s += a[i].split('\\n')[ii].strip() + ' '\n",
    "    return s\n",
    "\n",
    "def kkma_pos(a):\n",
    "    kkma = Kkma()\n",
    "    return kkma.pos(a)\n",
    "\n",
    "def __kkma_pos_filter(a):\n",
    "    \"\"\"\n",
    "    df['pos']를 받아 품사 필터링을 거쳐 해당 키워드 리스트 반환\n",
    "    \"\"\"\n",
    "    pos_ls = ['NNG','NNP','VA','UN','XR','MAG','ECE']\n",
    "    ls = []\n",
    "    s = \"\"\n",
    "    for i in range(len(a)):\n",
    "        #NNG(보통 명사), NNP(고유 명사), VA(형용사), XR(어근), MAG(일반 부사), UN(명사추정범주)\n",
    "        if a[i][1] in pos_ls:\n",
    "            s += a[i][0] + ','\n",
    "    ls.append(s)\n",
    "    return ls\n",
    "\n",
    "def __rating_filter(a):\n",
    "    if a == '3' or a == '4' or a == '5':\n",
    "        return 1\n",
    "        # 긍정\n",
    "    else:\n",
    "        return 0\n",
    "        # 부정\n",
    "        \n",
    "def Vectorizer_train(df_train, keyword, stop_words=None):\n",
    "    \"\"\"\n",
    "    df_train의 'pos_filtered' column을 받아 vectorized df를 생성해주는 함수\n",
    "    \"\"\"\n",
    "    train_corpus = []\n",
    "    for i in range(len(df_train['pos_filtered'])):\n",
    "        train_corpus.append(df_train['pos_filtered'][i][0])\n",
    "\n",
    "    vect = CountVectorizer(token_pattern=r\"\\b\\w+\\b\", stop_words=stop_words) # 한 글자도 corpus에 포함될 수 있게 해주는 정규표현식\n",
    "    vect.fit(train_corpus)\n",
    "    \n",
    "    pickle.dump(vect, open(\"save_vect_pkl/vect_{}.pkl\".format(keyword), \"wb\"))\n",
    "\n",
    "    vect_ls = []\n",
    "    for i in range(len(df_train)):\n",
    "        vect_ls.append(vect.transform(df_train['pos_filtered'][i]).toarray()[0])\n",
    "        # 리스트안의 리스트로 반환되기 때문에 vect_ls 안에 append하기 전에 [0]로 꺼내줌\n",
    "    \n",
    "    # 문자열 하나를 문장으로 간주\n",
    "    # corpus에는 여러 문장이 하나의 리스트 안의 문자열 요소로 들어가야 하고, ['an apple is red', 'the boy is young']\n",
    "    # transform할때는 한 문장이 하나의 리스트 안의 문자열 요소로 들어가야 함 ['an apple is red']\n",
    "    \n",
    "    df_vec = pd.DataFrame(vect_ls)\n",
    "    \n",
    "    return df_vec\n",
    "\n",
    "def Vectorizer_test(df_input, keyword):\n",
    "    \"\"\"\n",
    "    df_input의 'pos_filtered' column을 받아 vectorized df를 생성해주는 함수\n",
    "    df와 vect.vocabulary_를 반환\n",
    "    \"\"\"\n",
    "    vect = pickle.load(open(\"save_vect_pkl/vect_{}.pkl\".format(keyword), \"rb\"))\n",
    "    \n",
    "    vect_ls = []\n",
    "    for i in range(len(df_input)):\n",
    "        vect_ls.append(vect.transform(df_input['pos_filtered'][i]).toarray()[0])\n",
    "        # 리스트안의 리스트로 반환되기 때문에 vect_ls 안에 append하기 전에 [0]로 꺼내줌\n",
    "    \n",
    "    # 문자열 하나를 문장으로 간주\n",
    "    # corpus에는 여러 문장이 하나의 리스트 안의 문자열 요소로 들어가야 하고, ['an apple is red', 'the boy is young']\n",
    "    # transform할때는 한 문장이 하나의 리스트 안의 문자열 요소로 들어가야 함 ['an apple is red']\n",
    "    \n",
    "    df_vec = pd.DataFrame(vect_ls)\n",
    "\n",
    "    return df_vec, vect.vocabulary_ \n",
    "    \n",
    "def top_word_negative(X_test, y_test_pred, df_test, pos_voca, voca, word_cnt=20):\n",
    "    \"\"\"\n",
    "    pos_voca에는 단어와 pos 정보가 담겨있고\n",
    "    voca에는 단어와 vect모델 안에서의 단어별 index 정보가 담겨있다\n",
    "    \"\"\"\n",
    "    y_test_pred = pd.DataFrame(y_test_pred, columns=['prediction'])\n",
    "    pred_n_test = pd.concat([y_test_pred, X_test], axis=1)\n",
    "    top_word = pd.DataFrame(pred_n_test[pred_n_test['prediction']==0].sum().sort_values(ascending=False), columns=['count']).reset_index()\n",
    "    # reset_index()하면 원래 series에서 갖고있던 index를 value로 만들어줌\n",
    "    \n",
    "    top_word = top_word[top_word['count'] > 0]\n",
    "\n",
    "    def match_word(a):\n",
    "        for key, value in voca.items():\n",
    "            if value == a:\n",
    "                return key\n",
    "            \n",
    "    def real_pos(a):\n",
    "        for i in range(len(pos_voca)):\n",
    "            if a == pos_voca[i][0]:\n",
    "                return pos_voca[i][1]        \n",
    "    \n",
    "    top_word['word'] = top_word['index'].apply(match_word)\n",
    "    top_word['pos'] = top_word['word'].apply(real_pos)\n",
    "    \n",
    "    top_word = top_word[top_word['pos'].isin(['NNG','NNP', 'XR', 'UN'])].reset_index()[:word_cnt]\n",
    "    \n",
    "    def review_return(a):\n",
    "        idx_ls = list(pred_n_test[(pred_n_test['prediction']==0)&(pred_n_test[a] >= 1)].index)\n",
    "        return list(df_test[df_test.index.isin(idx_ls)]['full_review'].values)\n",
    "        \n",
    "    top_word['review'] = top_word['index'].apply(review_return)\n",
    "    \n",
    "    return top_word[['index','word', 'pos', 'count', 'review']]\n",
    "\n",
    "\n",
    "def top_word_positive(X_test, y_test_pred, df_test, pos_voca, voca, word_cnt=20):\n",
    "    \"\"\"\n",
    "    pos_voca에는 단어와 pos 정보가 담겨있고\n",
    "    voca에는 단어와 vect모델 안에서의 단어별 index 정보가 담겨있다\n",
    "    \"\"\"\n",
    "    y_test_pred = pd.DataFrame(y_test_pred, columns=['prediction'])\n",
    "    pred_n_test = pd.concat([y_test_pred, X_test], axis=1)\n",
    "    top_word = pd.DataFrame(pred_n_test[pred_n_test['prediction']==1].sum().sort_values(ascending=False), columns=['count']).reset_index()\n",
    "    # reset_index()하면 원래 series에서 갖고있던 index를 value로 만들어줌\n",
    "    \n",
    "    top_word_ = top_word[top_word['index'] != 'prediction'].reset_index(drop=True)\n",
    "    # prediction이 1이기 때문에 count값이 정수로 생기고, 그 row를 삭제해줌\n",
    "    top_word = top_word[top_word['count'] > 0]\n",
    "\n",
    "    def match_word(a):\n",
    "        for key, value in voca.items():\n",
    "            if value == a:\n",
    "                return key\n",
    "            \n",
    "    def real_pos(a):\n",
    "        for i in range(len(pos_voca)):\n",
    "            if a == pos_voca[i][0]:\n",
    "                return pos_voca[i][1]        \n",
    "    \n",
    "    top_word['word'] = top_word['index'].apply(match_word)\n",
    "    top_word['pos'] = top_word['word'].apply(real_pos)\n",
    "    \n",
    "    top_word = top_word[top_word['pos'].isin(['NNG','NNP', 'XR', 'UN'])].reset_index()[:word_cnt]\n",
    "    \n",
    "    def review_return(a):\n",
    "        idx_ls = list(pred_n_test[(pred_n_test['prediction']==1)&(pred_n_test[a] >= 1)].index)\n",
    "        return list(df_test[df_test.index.isin(idx_ls)]['full_review'].values)\n",
    "        \n",
    "    top_word['review'] = top_word['index'].apply(review_return)\n",
    "    \n",
    "    return top_word[['index','word', 'pos', 'count', 'review']]\n",
    "\n",
    "def top_word_word(df_top_word):\n",
    "    return list(df_top_word['word'].values)\n",
    "\n",
    "def top_word_count(df_top_word):\n",
    "    # jsonify에서 np.int는 오류나므로 int로 형변환해주어야 함\n",
    "    return [int(val) for val in df_top_word['count'].values]\n",
    "\n",
    "def top_word_review(df_top_word):\n",
    "    return list(df_top_word['review'].values)    \n",
    "    \n",
    "def neg_or_pos(y_test_pred):\n",
    "    \"\"\"\n",
    "    y_test_pred를 받아서 negative 댓글 개수와 positive 댓글 개수를 int로 반환\n",
    "    \"\"\"\n",
    "    y_test_pred = pd.DataFrame(y_test_pred, columns=['prediction'])\n",
    "    neg_or_pos = y_test_pred.groupby(by='prediction').size().reset_index(name='count')\n",
    "    neg = int(list(neg_or_pos[neg_or_pos['prediction']==0]['count'].values)[0])\n",
    "    pos = int(list(neg_or_pos[neg_or_pos['prediction']==1]['count'].values)[0])\n",
    "    return neg, pos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
